{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in Python once, it should take effect permanently\n",
    "from notebook.services.config import ConfigManager\n",
    "c = ConfigManager()\n",
    "c.update('notebook', {\"CodeCell\": {\"cm_config\": {\"autoCloseBrackets\": False}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "from os import path\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import glob\n",
    "\n",
    "# Imports url\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "\n",
    "#Wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the html page of the Friends episode transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = './season/'\n",
    "filename = '0101.html'\n",
    "\n",
    "def open_html(filename_html):\n",
    "    '''\n",
    "    Import html screenplay file.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    filename_html - String. File name.\n",
    "    \n",
    "    Return:\n",
    "    ------\n",
    "    File.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    filename = path+filename_html\n",
    "    \n",
    "    f = open(filename, 'r').read()\n",
    "    #print(f)\n",
    "    return f\n",
    "\n",
    "#filename = './season/0101.html'\n",
    "#f = open(filename, \"r\").read()\n",
    "#print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open_html(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get entire season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_episodes(path, season):\n",
    "    '''\n",
    "    Creates a html list with all the episodes in a season.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    path - String. Path to a season.\n",
    "    season - String. Conins characters to recognize a season. For example: '01*.html' will give all episodes in the first season.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    all_episodes_in_a_season - A list containing all html data for each episode in a season.\n",
    "    '''\n",
    "    \n",
    "    list_of_episodes = glob.glob(path+season)\n",
    "    \n",
    "    all_episodes_in_a_season = []\n",
    "    for episode in list_of_episodes:\n",
    "        f = open(episode, 'r').read()\n",
    "        all_episodes_in_a_season.append(f)\n",
    "        \n",
    "    return all_episodes_in_a_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_season = '01*.html'\n",
    "first_season_episodes = all_episodes(path, first_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(first_season_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert html into readable text using html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_html_to_text(file):\n",
    "    '''\n",
    "    Convert html file into text file. \n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    file - Html file. \n",
    "    \n",
    "    Return:\n",
    "    ------\n",
    "    episode - txt file, converted from html.\n",
    "    '''\n",
    "    \n",
    "    h = html2text.HTML2Text()\n",
    "    # Ignore converting links from HTML\n",
    "    h.ignore_links = True\n",
    "    print(h.handle(file))\n",
    "    episode = h.handle(file)\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_episode = convert_html_to_text(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get txt for all episodes in a season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_season_html_to_text(all_episodes_in_a_season):\n",
    "    '''\n",
    "    Convert html file into text file. \n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    all_episodes_in_a_season - A list containing all html data for each episode in a season/\n",
    "    \n",
    "    Return:\n",
    "    ------\n",
    "    all_episodes_in_a_season_txt - A list of all episodes in a season as txt file, converted from html.\n",
    "    '''\n",
    "    \n",
    "    h = html2text.HTML2Text()\n",
    "    # Ignore converting links from HTML\n",
    "    h.ignore_links = True\n",
    "    #print(h.handle(file))\n",
    "    \n",
    "    all_episodes_in_a_season_txt = []\n",
    "    for episode in all_episodes_in_a_season: \n",
    "        all_episodes = h.handle(episode)\n",
    "        all_episodes_in_a_season_txt.append(all_episodes)\n",
    "    return all_episodes_in_a_season_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_episodes_in_a_season_txt = convert_season_html_to_text(first_season_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_episodes_in_a_season_txt))\n",
    "\n",
    "print(all_episodes_in_a_season_txt[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stopwords_to_wordcloud(stop_friends_on_off):\n",
    "    '''\n",
    "    Set on and off stopwords - whether to use Friends names or not. If 'True' it will add Friends names to stopwords.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    stop_friends_on_off - True/False statement.\n",
    "    \n",
    "    Return:\n",
    "    ------\n",
    "    stopwords - list of the used stopwords.\n",
    "    '''\n",
    "    \n",
    "    stopwords = set(STOPWORDS) #set(STOPWORDS) for default exclusion\n",
    "    \n",
    "    stopwords.add(\"Scene\")\n",
    "    print(stopwords)\n",
    "    # Need to add stopwords for Frinds if I don't want to show their names\n",
    "    stop_friends = stop_friends_on_off\n",
    "\n",
    "    if stop_friends == True:\n",
    "        stopwords.add(\"Monica\")\n",
    "        stopwords.add(\"Rachel\")\n",
    "        stopwords.add(\"Ross\")\n",
    "        stopwords.add(\"Phoebe\")\n",
    "        stopwords.add(\"Chandler\")\n",
    "        stopwords.add(\"Joey\")\n",
    "        print('Friends names will be excluded.')\n",
    "    else:\n",
    "        print('Firends names will be included.')\n",
    "\n",
    "    return stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = add_stopwords_to_wordcloud(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_font_size = 100\n",
    "min_font_size = 20\n",
    "bck_color = 'white'\n",
    "#width = 500\n",
    "#height = 300\n",
    "width=1600\n",
    "height=800\n",
    "colourmap = plt.cm.cividis_r\n",
    "relative_scaling = 1 # relative scaling sets how to adjust the font sizes based on frequency\n",
    "                    # relative_scaling == 1.0 means frequency dictates font-size -> Hides low-frequency words\n",
    "                    # relative_scaling == 0.0 means rank dictates the relative font-size -> hides how frequently a word might appear\n",
    "\n",
    "collocations = False # if true, it will group phrases; if false it will take single words\n",
    "\n",
    "def generate_wordcloud_bilinear(episode, max_font_size ):\n",
    "    '''\n",
    "    Make a wordcloud based on the episode. Use bilinear interpolation and max font size.\n",
    "    \n",
    "    Parametes:\n",
    "    ---------\n",
    "    episode - txt of the loaded episode.\n",
    "    font_size - Integer. Maximum font size used on the image.\n",
    "    \n",
    "    Return:\n",
    "    ------\n",
    "    Makes a wordcloud and plots it.\n",
    "    '''\n",
    "    \n",
    "    # lower max_font_size\n",
    "    wordcloud = WordCloud(width=width, height=height, background_color=bck_color, \n",
    "                          min_font_size=min_font_size, stopwords=stopwords, colormap = colourmap,\n",
    "                         relative_scaling=relative_scaling, collocations=collocations).generate(episode)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # The pil way (if you don't have matplotlib)\n",
    "    # image = wordcloud.to_image()\n",
    "    # image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_wordcloud_bilinear(first_episode, max_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCloud for each episode in a season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for each_ep in np.arange(0, len(all_episodes_in_a_season_txt), 1):\n",
    "#    generate_wordcloud_bilinear(all_episodes_in_a_season_txt[each_ep], max_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCloud with a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image = 'friends_couch.jpg'\n",
    "\n",
    "def generate_wordcloud_with_mask(mask_image, episode):\n",
    "    '''\n",
    "    Make a wordcloud using image as a mask.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    mask_image - Image. Used as a mask.\n",
    "    episode - txt file. \n",
    "    \n",
    "    Return:\n",
    "    ------\n",
    "    Saves wordcloud figure and plots the output.\n",
    "    '''\n",
    "\n",
    "    friends_mask = np.array(Image.open(mask_image))\n",
    "\n",
    "    wc = WordCloud(width=width, height=height, background_color=\"white\", max_words=2000, mask=friends_mask,\n",
    "               stopwords=stopwords, contour_width=2, min_font_size=min_font_size, contour_color='grey', \n",
    "                  colormap = colourmap).generate(episode)\n",
    "\n",
    "    # store to file\n",
    "    wc.to_file(\"F.png\")\n",
    "    # show\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_wordcloud_with_mask(mask_image, first_episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Friend lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#friend_name = '**Monica:**'\n",
    "#friend_name = '**Rachel:**'\n",
    "#friend_name = '**Ross:**'\n",
    "#friend_name = '**Joey:**'\n",
    "friend_name = '**Phoebe:**'\n",
    "#friend_name = '**Chandler:**'\n",
    "\n",
    "def get_friend_line(friend_name, episode):\n",
    "    '''\n",
    "    Get the lines of a friend in an episode. These lines can include (one_friend) or exclude (one_friend_clear) the scene description.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    friend_name - Modified string of a friend nema; e.g. if you want Monica, you type: '**Monica:**'\n",
    "    episode - .txt file, converted from html in a function convert_html_to_text.\n",
    "\n",
    "    Return:\n",
    "    ------\n",
    "\n",
    "    one_friend - Strings. Contain all lines of a friend.\n",
    "    one_friend_clear - Strings. Contain all lines of a friend withoud scene description.\n",
    "        \n",
    "    '''\n",
    "    # Import episode into the testfile.txt\n",
    "    file_episode = open('testfile.txt','w', encoding='utf-8') \n",
    "    file_episode.write(episode) \n",
    "    \n",
    "    # Search friend lines\n",
    "    searchquery = friend_name\n",
    "    # From the episode file (testfile) read and write all friend lines into test_friend file.\n",
    "    with open('testfile.txt', encoding='utf-8') as f1:\n",
    "        with open('test_friend.txt', 'w', encoding='utf-8') as f2:\n",
    "            lines = f1.readlines()\n",
    "            for i, line in enumerate(lines):\n",
    "                # Add lines that starts with searcquery\n",
    "                if line.startswith(searchquery):\n",
    "                    f2.write(line)\n",
    "                    \n",
    "                    #Sometimes there are multiple lines, but not all starts with searchquer\n",
    "                    #Add them to the list if they dont start with ** because that would mean different Friend is speaking                       \n",
    "                    if not lines[i+1].startswith('**'):\n",
    "                        f2.write(lines[i+1])\n",
    "                    \n",
    "                        # Need to check several levels whether it is true or not\n",
    "                        if not lines[i+2].startswith('**'):\n",
    "                            f2.write(lines[i+2])\n",
    "                            \n",
    "                            if not lines[i+3].startswith('**'):\n",
    "                                f2.write(lines[i+3])\n",
    "                                \n",
    "                                if not lines[i+4].startswith('**'):\n",
    "                                    f2.write(lines[i+4])\n",
    "                                    \n",
    "                                    if not lines[i+5].startswith('**'):\n",
    "                                        f2.write(lines[i+5])\n",
    "                                        \n",
    "                \n",
    "    file = open('test_friend.txt', 'r',encoding='utf-8') \n",
    "    one_friend = file.read();\n",
    "    \n",
    "    # Remove text within [] and () brackets. These lines are scene description.\n",
    "    one_friend_tmp = re.sub( \"\\[[^\\]]*\\]\", \"\", one_friend) # Removes []\n",
    "    one_friend_clear = re.sub('\\([^)]*\\)', \"\",one_friend_tmp) # Removes ()\n",
    "    \n",
    "    return one_friend, one_friend_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoebe, phoebe_clear = get_friend_line(friend_name, first_episode)\n",
    "#print(phoebe_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoebe_s = []\n",
    "phoebe_clear_s = []\n",
    "\n",
    "for each_ep in np.arange(0, len(all_episodes_in_a_season_txt), 1):\n",
    "    phoebe_tmp, phoebe_clear_tmp = get_friend_line(friend_name, all_episodes_in_a_season_txt[each_ep])\n",
    "    \n",
    "    phoebe_s.append(phoebe_tmp)\n",
    "    phoebe_clear_s.append(phoebe_clear_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIFFERENT FORMATING FOR THE EPISODE\n",
    "print(phoebe_clear_s[15]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_wordcloud_bilinear(phoebe_clear, max_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCloud per season per Friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for each_ep in np.arange(0, len(phoebe_clear_s), 1):\n",
    "    try:\n",
    "        generate_wordcloud_bilinear(phoebe_clear_s[each_ep],  max_font_size)\n",
    "    \n",
    "    # I'm raising value error because s01e16 is formated differently, thus text for a friend is not detected at the moment\n",
    "    except ValueError:\n",
    "        pass\n",
    "        print('There is an error in episode {0}'.format(each_ep+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count words and plot frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If I want entire season I need to remove nested list\n",
    "#phoebe_clear_season = functools.reduce(operator.concat, phoebe_clear_s)\n",
    "\n",
    "#print(flat_list)\n",
    "\n",
    "words = []\n",
    "\n",
    "for i in np.arange(0, len(phoebe_clear_s), 1):\n",
    "# Use Counter to count the words; It will be dictionary\n",
    "    words_count = Counter(map(str.lower, phoebe_clear_s[i].split()))\n",
    "    words.append(words_count)\n",
    "\n",
    "dataframe = []\n",
    "for i in np.arange(0, len(words), 1):\n",
    "    \n",
    "    # Convert counted words into pandas dataframe\n",
    "    df = pd.DataFrame.from_dict(words[i], orient='index').reset_index()\n",
    "    dataframe.append(df)\n",
    "\n",
    "    \n",
    "print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_count = []\n",
    "\n",
    "for i in np.arange(0, len(dataframe), 1):\n",
    "\n",
    "    try:\n",
    "    \n",
    "        letter_i = dataframe[i][0] [dataframe[i]['index']=='i']\n",
    "        i_count.append(letter_i.values)\n",
    "\n",
    "    except KeyError:\n",
    "        pass\n",
    "        print('No value at position {0}'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i_count)\n",
    "print(len(i_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If I want entire season I need to remove nested list\n",
    "phoebe_clear_season = functools.reduce(operator.concat, phoebe_clear_s)\n",
    "\n",
    "#print(flat_list)\n",
    "\n",
    "# Use Counter to count the words; It will be dictionary\n",
    "words_count = Counter(map(str.lower, phoebe_clear_season.split()))\n",
    "\n",
    "# Convert counted words into pandas dataframe\n",
    "df = pd.DataFrame.from_dict(words_count, orient='index').reset_index()\n",
    "\n",
    "# Rename colums\n",
    "df = df.rename(columns={'index':'word', 0:'count'})\n",
    "\n",
    "# Sort by the 'count' values, highest first\n",
    "df = df.sort_values(['count'], ascending=[False])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(df['word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_x_words = 15\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(15,10))\n",
    "\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.bar(df['word'][0:first_x_words], df['count'][0:first_x_words], color='lightgrey', edgecolor='k')\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "plt.xlabel('Words', fontsize=24)\n",
    "plt.ylabel('Count', fontsize=22)\n",
    "\n",
    "\n",
    "for bar in ax.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x()+bar.get_width()/2.,\n",
    "            height + 0.2,\n",
    "            '{:1.2f}'.format(height),\n",
    "            ha=\"center\",fontsize=18) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count 'I' per season per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(1, len(i_count)+1, 1)\n",
    "i_values = []\n",
    "\n",
    "for i in np.arange(0, len(i_count), 1):\n",
    "    try:\n",
    "        value = i_count[i][0]\n",
    "        i_values.append(value)\n",
    "    except IndexError:\n",
    "        i_values.append(0)\n",
    "        \n",
    "fig, ax = plt.subplots(1, figsize=(15,10))\n",
    "\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.bar(A, i_values, color='lightgrey', edgecolor='k', label='Phoebe')\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "plt.xlabel('Episode', fontsize=24)\n",
    "plt.ylabel('\\' I \\' [counts]', fontsize=22)\n",
    "plt.legend(loc=0, fontsize=20)\n",
    "\n",
    "for bar in ax.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x()+bar.get_width()/2.,\n",
    "            height + 0.2,\n",
    "            '{}'.format(height),\n",
    "            ha=\"center\",fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_count[22][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
